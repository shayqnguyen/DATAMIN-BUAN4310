---
title: "BUAN4310 LR Lab 2"
author: "Shayla Nguyen"
date: "2024-10-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
1. PREPARE THE DATA
```{r}
# Import the data
library(readr)
library(ggplot2)
admin_df <- read_csv("SystemAdministrators_v2.csv")
```

```{r}
head(admin_df)
```
```{r}
str(admin_df)
```

2. CREATE A SCATTER PLOT
```{r}
# Scatter Plot
ggplot(admin_df, aes(x = Training, y = Experience, 
                     color = as.factor(Completed.task))) +
  geom_point() +
  scale_color_manual(values = c("pink", "purple")) +
  labs(title = "Scatter Plot of Training vs. Experience",
       x = "Training",
       y = "Experience",
       color = "Completed Task") +
  theme_dark()
```

```{r}
# 1. Load Data
songs <- read.csv("american_idol_songs_v8.csv", header = TRUE)
head(songs, 10)
```


```{r}
# 2. PreProcessing
## 2.1 Filter Variables
# Factorizing 'Advance' column
songs$Advance <- as.factor(songs$Advance)

# Keep necessary columns
songs <- songs[, c(4, 6, 10, 11, 7)]
head(songs)
```


```{r}
## 2.2 Training-Validation Split
# Set seed for reproducibility
set.seed(666)

# Split the data into training and validation sets (70%-30%)
train_index <- sample(1:nrow(songs), 0.7 * nrow(songs))
valid_index <- setdiff(1:nrow(songs), train_index)

# Create training and validation sets
train_df <- songs[train_index, ]
valid_df <- songs[valid_index, ]

# Check split
nrow(train_df)
nrow(valid_df)
```


```{r}
# 3. Logistic Regression
library(caret)

# Train logistic regression model
logistic_reg <- train(Advance ~ Song_Avg_Rtg + Avg_Song_Age + Expectation + Artiste_Rating,
                      data = train_df, method = "glm")

# Summary of the model
summary(logistic_reg)

# Variable importance
varImp(logistic_reg)
```


```{r}
# Predict the training set
logistic_reg_pred_train <- predict(logistic_reg, 
                                   newdata = train_df, type = "raw")
logistic_reg_pred_train_prob <- predict(logistic_reg, 
                                        newdata = train_df, type = "prob")

# Predict the validation set
logistic_reg_pred_valid <- predict(logistic_reg, 
                                   newdata = valid_df, type = "raw")
logistic_reg_pred_valid_prob <- predict(logistic_reg, 
                                        newdata = valid_df, type = "prob")
```


```{r}
# 4. Model Evaluation
## Multicollinearity Check
library(Hmisc)
```


```{r}
# Calculate correlation matrix
rcorr(as.matrix(train_df[, -c(5)]))

# Confusion Matrix for Training Data
confusionMatrix(logistic_reg_pred_train, train_df$Advance, positive = "1")

# Confusion Matrix for Validation Data
confusionMatrix(logistic_reg_pred_valid, valid_df$Advance, positive = "1")

```


```{r}
# ROC Curve for Training Data
library(pROC)

# ROC curve for the training data
roc_train <- roc(train_df$Advance, logistic_reg_pred_train_prob[, 2])
plot(roc_train, col = "blue", main = "ROC Curve (Training Data)")

# ROC curve for the validation data
roc_valid <- roc(valid_df$Advance, logistic_reg_pred_valid_prob[, 2])
plot(roc_valid, col = "red", main = "ROC Curve (Validation Data)")
```


```{r}
# 5. PREDICTION FOR NEW SONGS
## Example of how to predict for new songs (new dataset for new songs)

# Input new data (replace with your actual new song data)
library(readr)
new_songs_df <- read_csv("new_songs.csv")

# Predict task completion for the new songs
new_songs_pred <- predict(logistic_reg, newdata = new_songs_df, type = "raw")
new_songs_pred_prob <- predict(logistic_reg, newdata = new_songs_df, type = "prob")
```


```{r}
# Display predictions and probabilities for the new songs
new_songs_df$Predicted_Advance <- new_songs_pred
new_songs_df$Predicted_Probabilities <- new_songs_pred_prob

# View the predictions
new_songs_df
new_songs_pred_prob
new_songs_pred

```

